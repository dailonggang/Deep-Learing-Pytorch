# 文件说明
### 复现的网络大多包含以下几个文件
* model.py：模型文件
* train.py： 调用模型训练的文件
* predict.py： 调用模型进行预测的文件
* class_indices.json： 训练数据集对应的标签文件

### 3.2 
--------------
### 2021
* Feng et al, DARDet: A Dense Anchor-free Rotated Object Detector in Aerial Images.注：无锚框自然图像 [[paper](https://arxiv.org/pdf/2110.01025.pdf)][[code](https://github.com/zf020114/DARDet)]
* Steven Lang et al, DAFNe: A One-Stage Anchor-Free Deep Model for Oriented Object Detection.遥感目标检测 [[paper](https://arxiv.org/pdf/2109.06148.pdf)][[code](https://github.com/steven-lang/DAFNe)]
* Jiaming Han et al, ReDet: A Rotation-equivariant Detector for Aerial Object Detection.遥感旋转目标检测 [[paper](https://arxiv.org/pdf/2103.07733.pdf)][[code]( https:
//github.com/csuhan/ReDet)]
* Gong Cheng, et al, Anchor-free Oriented Proposal Generator for Object Detection.遥感旋转目标检测 [[paper](https://arxiv.org/pdf/2110.01931.pdf)][[code](https://github.com/jbwang1997/AOPG)]

### 图像分类(Classification)-Papers
* LeNet [[paper](http://lushuangning.oss-cn-beijing.aliyuncs.com/CNN%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97/Gradient-Based_Learning_Applied_to_Document_Recognition.pdf)]
* AlexNet [[paper]()]http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
* ZFNet[[paper]()]
* VGG https://arxiv.org/abs/1409.1556
* GoogLeNet, Inceptionv1(Going deeper with convolutions) https://arxiv.org/abs/1409.4842
* Batch Normalization https://arxiv.org/abs/1502.03167
* Inceptionv3(Rethinking the Inception Architecture for Computer Vision) https://arxiv.org/abs/1512.00567
* Inceptionv4, Inception-ResNet https://arxiv.org/abs/1602.07261
* Xception(Deep Learning with Depthwise Separable Convolutions) https://arxiv.org/abs/1610.02357
* ResNet https://arxiv.org/abs/1512.03385
* ResNeXt https://arxiv.org/abs/1611.05431
* DenseNet https://arxiv.org/abs/1608.06993
* NASNet-A(Learning Transferable Architectures for Scalable Image Recognition) https://arxiv.org/abs/1707.07012
* SENet(Squeeze-and-Excitation Networks) https://arxiv.org/abs/1709.01507
* MobileNet(v1) https://arxiv.org/abs/1704.04861
* MobileNet(v2) https://arxiv.org/abs/1801.04381
* MobileNet(v3) https://arxiv.org/abs/1905.02244
* ShuffleNet(v1) https://arxiv.org/abs/1707.01083
* ShuffleNet(v2) https://arxiv.org/abs/1807.11164
* Bag of Tricks for Image Classification with Convolutional Neural Networks https://arxiv.org/abs/1812.01187
* EfficientNet(v1) https://arxiv.org/abs/1905.11946
* EfficientNet(v2) https://arxiv.org/abs/2104.00298
* CSPNet https://arxiv.org/abs/1911.11929
* RegNet https://arxiv.org/abs/2003.13678
* NFNets(High-Performance Large-Scale Image Recognition Without Normalization) https://arxiv.org/abs/2102.06171
* Vision Transformer https://arxiv.org/abs/2010.11929
* DeiT(Training data-efficient image transformers ) https://arxiv.org/abs/2012.12877
* Swin Transformer https://arxiv.org/abs/2103.14030
* Swin Transformer V2: Scaling Up Capacity and Resolution https://arxiv.org/abs/2111.09883
* BEiT: BERT Pre-Training of Image Transformers https://arxiv.org/abs/2106.08254
* MAE(Masked Autoencoders Are Scalable Vision Learners) https://arxiv.org/abs/2111.06377
* ConvNeXt(A ConvNet for the 2020s) https://arxiv.org/abs/2201.03545

